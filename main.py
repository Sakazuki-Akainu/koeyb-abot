import os
import asyncio
import glob
import shutil
import time
import re
import logging
import sys
import random
import string
import urllib.parse
import subprocess
from aiohttp import web
from pyrogram import Client, filters, idle
from curl_cffi import requests as cffi_requests

# --- LOGGING SETUP ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
LOGGER = logging.getLogger("Bot")

# --- 1. CONFIGURATION ---
try:
    API_ID = int(os.environ.get('API_ID'))
    API_HASH = os.environ.get('API_HASH')
    BOT_TOKEN = os.environ.get('BOT_TOKEN')

    def load_channel(key):
        val = os.environ.get(key)
        if not val: return None
        try: return int(val)
        except ValueError: return val

    CHANNEL_1 = load_channel('CHANNEL_1')
    CHANNEL_2 = load_channel('CHANNEL_2')
    CHANNEL_3 = load_channel('CHANNEL_3')

except Exception as e:
    LOGGER.error(f"‚ùå Configuration Error: {e}")
    API_ID, API_HASH, BOT_TOKEN = 0, "", ""

DOWNLOAD_DIR = "./downloads"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)
ACTIVE_TASKS = {}
SETTINGS = {"ch1": False, "ch2": False, "ch3": True}

app = Client("anime_bot", api_id=API_ID, api_hash=API_HASH, bot_token=BOT_TOKEN, ipv6=False, workers=16)

# --- 2. HEALTH CHECK SERVER ---
async def health_check(request):
    return web.Response(text="Bot is Running!", status=200)

async def start_web_server():
    server = web.Application()
    server.router.add_get("/", health_check)
    runner = web.AppRunner(server)
    await runner.setup()
    site = web.TCPSite(runner, "0.0.0.0", 8000)
    await site.start()
    LOGGER.info("‚úÖ Health Check Server Started on Port 8000")

# --- 3. NETWORK ENGINE ---
def get_browser_session():
    session = cffi_requests.Session(impersonate="chrome124")
    # Generate Cookie
    ddg2_value = ''.join(random.choices(string.ascii_letters + string.digits, k=16))
    session.cookies.update({"__ddg2_": ddg2_value})
    session.headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
        "Referer": "https://animepahe.si/",
        "Origin": "https://animepahe.si",
    }
    LOGGER.info(f"üç™ Generated Cookie: {ddg2_value}")
    return session

# üü¢ FIXED: Regex handles attributes & finds 'source'
def solve_kwik_with_node(html_content):
    try:
        # Strategy 1: Find eval() script (Regex updated to handle <script type="...">)
        match = re.search(r"<script[^>]*>(eval\(.+?\))</script>", html_content, re.DOTALL)
        
        if match:
            js_code = match.group(1)
            # Bash script logic replacements
            js_code = js_code.replace("document", "process")
            js_code = js_code.replace("querySelector", "exit")
            js_code = js_code.replace("eval(", "console.log(")
            
            process = subprocess.run(
                ["node", "-e", js_code],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if process.returncode == 0:
                # Extract 'source' from node output
                source_match = re.search(r"source=['\"]([^'\"]+)['\"]", process.stdout)
                if source_match: 
                    LOGGER.info("‚úÖ Decoded via Node.js")
                    return source_match.group(1)
        
        # Strategy 2: Look for 'const source' directly (Your "Use Source" request)
        source_match = re.search(r"const\s+source\s*=\s*['\"]([^'\"]+)['\"]", html_content)
        if source_match:
            LOGGER.info("‚úÖ Found direct source (No Eval needed)")
            return source_match.group(1)

        # Strategy 3: Fallback - Any m3u8 link
        m3u8_match = re.search(r"(https?://[\w\-\.]+/[\w\-\.]+\.m3u8[^\"']*)", html_content)
        if m3u8_match:
            LOGGER.info("‚úÖ Found m3u8 via Fallback Regex")
            return m3u8_match.group(1)

        LOGGER.error("‚ùå Link extraction failed.")
        return None

    except Exception as e:
        LOGGER.error(f"‚ùå Node/Regex Error: {e}")
        return None

async def download_anime_episode(command_args, status_msg):
    name_match = re.search(r'-a\s+["\']([^"\']+)["\']', command_args)
    ep_match = re.search(r'-e\s+(\d+)', command_args)
    
    if not name_match or not ep_match:
        await status_msg.edit_text("‚ùå Usage: `/dl -a \"Name\" -e 1`")
        return None

    query = name_match.group(1)
    episode_num = int(ep_match.group(1))
    
    await status_msg.edit_text(f"üîç **Searching:** `{query}`")

    s = get_browser_session()
    
    try:
        # Search
        s.get("https://animepahe.si/", timeout=10)
        search_query = urllib.parse.quote(query)
        r = s.get(f"https://animepahe.si/api?m=search&q={search_query}", timeout=30)
        
        if r.status_code != 200:
            await status_msg.edit_text(f"‚ùå Search Error: {r.status_code}")
            return None
            
        data = r.json()
        if not data.get("data"):
            await status_msg.edit_text("‚ùå Anime not found.")
            return None
            
        anime = data["data"][0]
        session_id = anime["session"]
        title = anime["title"]
        
        await status_msg.edit_text(f"‚úÖ **{title}**\nüì• Finding Ep {episode_num}...")
        
        # Episodes
        await asyncio.sleep(1)
        r = s.get(f"https://animepahe.si/api?m=release&id={session_id}&sort=episode_asc&page=1", timeout=30)
        eps_data = r.json()

        target_session = None
        for ep in eps_data["data"]:
            if int(ep["episode"]) == episode_num:
                target_session = ep["session"]
                break
        
        if not target_session:
            await status_msg.edit_text(f"‚ùå Ep {episode_num} not found on Pg 1.")
            return None

        # Play Page
        play_url = f"https://animepahe.si/play/{session_id}/{target_session}"
        s.headers["Referer"] = "https://animepahe.si/"
        html_response = s.get(play_url, timeout=30)
        
        kwik_links = re.findall(r'(https?://kwik\.[a-z]+/e/\w+)', html_response.text)
        
        if not kwik_links:
            await status_msg.edit_text("‚ùå No stream links.")
            return None
            
        best_link = kwik_links[-1]
        LOGGER.info(f"üîó Found Kwik Link: {best_link}")
        
        # Kwik Page
        s.headers["Referer"] = play_url
        kwik_html = s.get(best_link, timeout=30).text
        
        # üü¢ DECRYPT
        m3u8 = solve_kwik_with_node(kwik_html)
        
        if not m3u8:
            await status_msg.edit_text("‚ùå **Failed to decrypt Kwik.**")
            return None
            
        # Download
        filename = f"{title} - Episode {episode_num}.mp4"
        filepath = os.path.join(DOWNLOAD_DIR, filename)
        
        await status_msg.edit_text(f"‚¨áÔ∏è **Downloading...**\nFile: `{filename}`")
        
        cmd = [
            "yt-dlp",
            "--external-downloader", "aria2c",
            "--external-downloader-args", "-x 16 -k 1M",
            "--referer", "https://kwik.cx/",
            "-o", filepath,
            m3u8
        ]
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if os.path.exists(filepath):
            return filepath
        else:
            LOGGER.error(f"DL Error: {stderr.decode()}")
            await status_msg.edit_text("‚ùå Download Failed (Aria2).")
            return None

    except Exception as e:
        LOGGER.error(f"Engine Error: {e}")
        await status_msg.edit_text(f"‚ùå Error: {e}")
        return None

# --- 4. HANDLERS ---
@app.on_message(filters.command("dl"))
async def dl_handler(client, message):
    chat_id = message.chat.id
    if chat_id in ACTIVE_TASKS: return await message.reply("‚ö†Ô∏è Busy.")
    
    cmd_text = message.text[4:]
    if not cmd_text: return await message.reply("Usage: `/dl -a \"Name\" -e 1`")
    
    ACTIVE_TASKS[chat_id] = True
    status_msg = await message.reply("‚è≥ **Initializing...**")
    
    try:
        filepath = await download_anime_episode(cmd_text, status_msg)
        
        if filepath:
            await status_msg.edit_text("üöÄ **Uploading...**")
            await client.send_document(chat_id, filepath, caption=f"‚úÖ **Done**\n`{os.path.basename(filepath)}`")
            os.remove(filepath)
            await status_msg.delete()
            
    except Exception as e:
        LOGGER.error(e)
    
    finally:
        del ACTIVE_TASKS[chat_id]

async def main():
    print("ü§ñ Bot Starting...", flush=True)
    await asyncio.gather(start_web_server(), app.start(), idle())
    await app.stop()

if __name__ == "__main__":
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    loop.run_until_complete(main())
